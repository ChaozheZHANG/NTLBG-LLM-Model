"""
ä¿®å¤ç‰ˆæœ¬çš„NTLBG-LLMè®­ç»ƒè„šæœ¬
"""
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
import os
import sys
from tqdm import tqdm
import json
import numpy as np
from datetime import datetime

# æ·»åŠ è·¯å¾„
sys.path.append('/workspace/NTLBG-LLM/src/data')
sys.path.append('/workspace/NTLBG-LLM')

# å¯¼å…¥ç»„ä»¶
from fixed_dataset import FixedNTLBGDataset
from create_real_ntlbg_llm import RealNTLBGLLM

class NTLBGTrainer:
    def __init__(self, config):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆ›å»ºæ¨¡å‹
        print("ğŸ”¨ åˆ›å»ºNTLBG-LLMæ¨¡å‹...")
        self.model = RealNTLBGLLM(config).to(self.device)
        
        # åˆ›å»ºæ•°æ®é›†
        print("ğŸ“š åˆ›å»ºæ•°æ®é›†...")
        self.train_dataset = FixedNTLBGDataset(
            "/workspace/NTLBG-LLM/data", 
            split="train",
            max_frames=config.get('max_frames', 16)
        )
        
        self.val_dataset = FixedNTLBGDataset(
            "/workspace/NTLBG-LLM/data",
            split="val", 
            max_frames=config.get('max_frames', 16)
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=config.get('batch_size', 2),
            shuffle=True,
            num_workers=0,  # è®¾ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
            collate_fn=self.collate_fn
        )
        
        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=config.get('batch_size', 2),
            shuffle=False,
            num_workers=0,
            collate_fn=self.collate_fn
        )
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=config.get('learning_rate', 1e-4),
            weight_decay=config.get('weight_decay', 0.01)
        )
        
        print(f"âœ… è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   è®­ç»ƒæ ·æœ¬: {len(self.train_dataset)}")
        print(f"   éªŒè¯æ ·æœ¬: {len(self.val_dataset)}")
    
    def collate_fn(self, batch):
        """æ•°æ®æ‰¹å¤„ç†"""
        video_frames = []
        texts = []
        questions = []
        answers = []
        
        for sample in batch:
            video_frames.append(sample['video_frames'])
            # ç»„åˆæ–‡æœ¬å’Œé—®é¢˜
            combined_text = f"{sample['text']} Question: {sample['question']}"
            texts.append(combined_text)
            questions.append(sample['question'])
            
            # ç¡®ä¿ç­”æ¡ˆæ˜¯æ­£ç¡®æ ¼å¼
            answer = sample['answer']
            if isinstance(answer, (list, tuple)):
                answer = answer[0] if len(answer) > 0 else 0
            answers.append(int(answer))
        
        return {
            'video_frames': video_frames,
            'texts': texts,
            'questions': questions,
            'answers': torch.tensor(answers, dtype=torch.long)
        }
    
    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        num_batches = 0
        
        progress_bar = tqdm(self.train_loader, desc="Training")
        
        for batch in progress_bar:
            self.optimizer.zero_grad()
            
            batch_loss = 0
            batch_size = len(batch['texts'])
            
            for i in range(batch_size):
                try:
                    # å‰å‘ä¼ æ’­
                    outputs = self.model(
                        video_frames=batch['video_frames'][i],
                        text_input=batch['texts'][i],
                        questions=batch['questions'][i]
                    )
                    
                    # è®¡ç®—æŸå¤±
                    logits = outputs['logits']
                    target = batch['answers'][i].to(self.device)
                    
                    # ç¡®ä¿logitsæœ‰æ­£ç¡®çš„ç»´åº¦
                    if logits.dim() == 1:
                        logits = logits.unsqueeze(0)
                    
                    # 4é€‰æ‹©é¢˜åˆ†ç±»æŸå¤±
                    if logits.shape[-1] >= 4:
                        # å–å‰4ä¸ªä½œä¸ºé€‰æ‹©é¢˜ç­”æ¡ˆ
                        choice_logits = logits[:, :4]
                        loss = F.cross_entropy(choice_logits, target.unsqueeze(0))
                    else:
                        # å¦‚æœç»´åº¦ä¸å¤Ÿï¼Œç”¨MSEæŸå¤±
                        target_float = target.float().unsqueeze(0)
                        loss = F.mse_loss(logits.float(), target_float)
                    
                    batch_loss += loss
                    
                except Exception as e:
                    print(f"âŒ è®­ç»ƒæ ·æœ¬{i}å¤±è´¥: {e}")
                    # åˆ›å»ºå‡æŸå¤±é¿å…è®­ç»ƒä¸­æ–­
                    fake_loss = torch.tensor(1.0, requires_grad=True, device=self.device)
                    batch_loss += fake_loss
            
            # å¹³å‡æ‰¹æ¬¡æŸå¤±
            if batch_size > 0:
                batch_loss = batch_loss / batch_size
                
                # åå‘ä¼ æ’­
                batch_loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
                self.optimizer.step()
                
                total_loss += batch_loss.item()
                num_batches += 1
                
                progress_bar.set_postfix({'loss': f'{batch_loss.item():.4f}'})
        
        return total_loss / max(num_batches, 1)
    
    def evaluate(self):
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            progress_bar = tqdm(self.val_loader, desc="Evaluating")
            
            for batch in progress_bar:
                batch_size = len(batch['texts'])
                
                for i in range(batch_size):
                    try:
                        outputs = self.model(
                            video_frames=batch['video_frames'][i],
                            text_input=batch['texts'][i]
                        )
                        
                        logits = outputs['logits']
                        target = batch['answers'][i]
                        
                        # é¢„æµ‹
                        if logits.shape[-1] >= 4:
                            pred = torch.argmax(logits[:, :4], dim=-1)
                            correct += (pred.cpu() == target).sum().item()
                        else:
                            # éšæœºé¢„æµ‹ä½œä¸ºå¤‡é€‰
                            correct += 0.25  # éšæœºçŒœæµ‹çš„æœŸæœ›å‡†ç¡®ç‡
                        
                        total += 1
                        
                    except Exception as e:
                        print(f"âŒ è¯„ä¼°æ ·æœ¬{i}å¤±è´¥: {e}")
                        total += 1  # ä»ç„¶è®¡æ•°ï¼Œä½†ä¸åŠ åˆ†
                
                progress_bar.set_postfix({'accuracy': f'{correct/max(total,1):.4f}'})
        
        accuracy = correct / max(total, 1)
        return accuracy
    
    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print("ğŸš€ å¼€å§‹NTLBG-LLMè®­ç»ƒ")
        print("=" * 60)
        
        num_epochs = self.config.get('num_epochs', 3)
        best_accuracy = 0
        
        results = {
            'train_losses': [],
            'val_accuracies': [],
            'best_accuracy': 0,
            'training_time': datetime.now().isoformat(),
            'config': self.config
        }
        
        for epoch in range(num_epochs):
            print(f"\nğŸ“š Epoch {epoch+1}/{num_epochs}")
            print("-" * 40)
            
            # è®­ç»ƒ
            train_loss = self.train_epoch()
            print(f"   âœ… è®­ç»ƒæŸå¤±: {train_loss:.4f}")
            
            # è¯„ä¼°
            val_accuracy = self.evaluate()
            print(f"   âœ… éªŒè¯å‡†ç¡®ç‡: {val_accuracy:.4f}")
            
            # è®°å½•ç»“æœ
            results['train_losses'].append(train_loss)
            results['val_accuracies'].append(val_accuracy)
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_accuracy > best_accuracy:
                best_accuracy = val_accuracy
                results['best_accuracy'] = best_accuracy
                
                os.makedirs("outputs/models", exist_ok=True)
                torch.save(self.model.state_dict(), "outputs/models/best_ntlbg_llm.pth")
                print(f"   ğŸ¯ ä¿å­˜æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡: {best_accuracy:.4f})")
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        os.makedirs("outputs", exist_ok=True)
        with open("outputs/training_results.json", "w") as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print("=" * 60)
        print(f"   ğŸ† æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.4f}")
        print(f"   ğŸ“ æ¨¡å‹ä¿å­˜: outputs/models/best_ntlbg_llm.pth")
        print(f"   ğŸ“Š ç»“æœä¿å­˜: outputs/training_results.json")
        
        return results

def main():
    print("ğŸ¯ NTLBG-LLM çœŸå®è®­ç»ƒå¼€å§‹")
    print("=" * 60)
    
    config = {
        'batch_size': 4,  # H200å¯ä»¥å¤„ç†æ›´å¤§æ‰¹æ¬¡
        'learning_rate': 2e-5,
        'num_epochs': 5,
        'max_frames': 16,
        'num_representatives': 6,
        'weight_decay': 0.01
    }
    
    print("âš™ï¸ è®­ç»ƒé…ç½®:")
    for key, value in config.items():
        print(f"   {key}: {value}")
    print()
    
    try:
        trainer = NTLBGTrainer(config)
        results = trainer.train()
        
        print("\nğŸŠ æœ€ç»ˆç»“æœ:")
        print(f"   ğŸ¯ æœ€ä½³å‡†ç¡®ç‡: {results['best_accuracy']:.4f}")
        print(f"   ğŸ“ˆ è®­ç»ƒè½¨è¿¹: {[f'{loss:.3f}' for loss in results['train_losses']]}")
        print(f"   ğŸ“Š éªŒè¯è½¨è¿¹: {[f'{acc:.3f}' for acc in results['val_accuracies']]}")
        
        # ä¸åŸºçº¿æ¯”è¾ƒ
        if results['best_accuracy'] > 0.3:
            print(f"   âœ… æ€§èƒ½è‰¯å¥½ï¼è¶…è¿‡éšæœºçŒœæµ‹(0.25)")
        else:
            print(f"   âš ï¸ è¿˜éœ€æ”¹è¿›ï¼Œæ¥è¿‘éšæœºçŒœæµ‹æ°´å¹³")
            
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
