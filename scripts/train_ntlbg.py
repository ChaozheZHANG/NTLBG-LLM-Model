#!/usr/bin/env python3
"""
NTLBG-LLMè®­ç»ƒè„šæœ¬
ç”¨æ³•: python scripts/train_ntlbg.py --config configs/ntlbg_base_config.json
"""

import os
import sys
import json
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.nn.utils import clip_grad_norm_
import numpy as np
from tqdm import tqdm
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging
from datetime import datetime
from collections import defaultdict
import random
import warnings

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from src.models.ntlbg_llm import create_ntlbg_llm
from src.data.datasets import create_dataloaders


def set_seed(seed: int = 42):
    """è®¾ç½®éšæœºç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def setup_logging(output_dir: str) -> logging.Logger:
    """è®¾ç½®æ—¥å¿—"""
    os.makedirs(output_dir, exist_ok=True)
    
    log_file = os.path.join(output_dir, f'training_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger(__name__)


def get_device_info():
    """è·å–è®¾å¤‡ä¿¡æ¯"""
    print("=== ç¯å¢ƒä¿¡æ¯ ===")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    return device


class LossWeightScheduler:
    """æŸå¤±æƒé‡åŠ¨æ€è°ƒåº¦å™¨"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.initial_weights = config['loss_weights']
        self.schedule_type = config.get('weight_schedule', 'static')
        self.warmup_steps = config.get('weight_warmup_steps', 1000)
    
    def get_weights(self, step: int, epoch: int) -> Dict[str, float]:
        """æ ¹æ®è®­ç»ƒæ­¥æ•°è¿”å›å½“å‰çš„æŸå¤±æƒé‡"""
        if self.schedule_type == 'static':
            return self.initial_weights
        
        elif self.schedule_type == 'progressive':
            # æ¸è¿›å¼æƒé‡è°ƒæ•´ï¼šæ—©æœŸä¸“æ³¨ä»»åŠ¡æŸå¤±ï¼ŒåæœŸå¢åŠ NTLBGçº¦æŸ
            progress = min(1.0, step / self.warmup_steps)
            
            weights = {}
            weights['task'] = self.initial_weights['task']
            weights['ntlbg'] = self.initial_weights['ntlbg'] * progress
            weights['alignment'] = self.initial_weights['alignment'] * (progress ** 0.5)
            weights['temporal'] = self.initial_weights['temporal'] * progress
            weights['info'] = self.initial_weights['info'] * progress
            
            return weights
        
        else:
            return self.initial_weights


class NTLBGTrainer:
    """NTLBG-LLMè®­ç»ƒå™¨"""
    
    def __init__(self, 
                 model: nn.Module,
                 train_dataloader: DataLoader,
                 val_dataloader: DataLoader,
                 config: Dict,
                 device: torch.device):
        self.model = model
        self.train_dataloader = train_dataloader
        self.val_dataloader = val_dataloader
        self.config = config
        self.device = device
        
        # å°†æ¨¡å‹ç§»åˆ°è®¾å¤‡
        self.model.to(device)
        
        # è®¾ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        self._setup_optimizer()
        self._setup_scheduler()
        
        # æŸå¤±æƒé‡è°ƒåº¦å™¨
        self.loss_weight_scheduler = LossWeightScheduler(config.get('loss_config', {}))
        
        # è®¾ç½®æ—¥å¿—
        self.logger = setup_logging(config['output_dir'])
        
        # æœ€ä½³æ¨¡å‹è·Ÿè¸ª
        self.best_val_loss = float('inf')
        self.best_model_path = None
        
        # è®­ç»ƒç»Ÿè®¡
        self.train_stats = {
            'total_steps': 0,
            'epoch': 0,
            'losses': [],
            'learning_rates': []
        }
    
    def _setup_optimizer(self):
        """è®¾ç½®ä¼˜åŒ–å™¨"""
        training_config = self.config['training_config']
        
        # åˆ†ç»„å‚æ•°ï¼šä¸åŒçš„å­¦ä¹ ç‡
        base_model_params = []
        ntlbg_params = []
        other_params = []
        
        for name, param in self.model.named_parameters():
            if not param.requires_grad:
                continue
                
            if 'base_llm' in name:
                base_model_params.append(param)
            elif any(module in name for module in ['ntlbg_attention', 'rich_constructor', 'temporal_aligner']):
                ntlbg_params.append(param)
            else:
                other_params.append(param)
        
        # ä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡
        param_groups = [
            {'params': base_model_params, 'lr': training_config['base_lr'] * 0.1},
            {'params': ntlbg_params, 'lr': training_config['base_lr']},
            {'params': other_params, 'lr': training_config['base_lr'] * 0.5}
        ]
        
        if training_config['optimizer'] == 'adamw':
            self.optimizer = optim.AdamW(
                param_groups,
                weight_decay=training_config['weight_decay'],
                eps=1e-8
            )
        elif training_config['optimizer'] == 'adam':
            self.optimizer = optim.Adam(param_groups)
        else:
            raise ValueError(f"Unsupported optimizer: {training_config['optimizer']}")
    
    def _setup_scheduler(self):
        """è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨"""
        training_config = self.config['training_config']
        
        total_steps = len(self.train_dataloader) * training_config['num_epochs']
        warmup_steps = int(total_steps * training_config['warmup_ratio'])
        
        if training_config['scheduler'] == 'cosine':
            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer, 
                T_max=total_steps,
                eta_min=training_config['base_lr'] * 0.01
            )
        elif training_config['scheduler'] == 'linear':
            def lr_lambda(step):
                if step < warmup_steps:
                    return step / warmup_steps
                else:
                    return max(0.01, (total_steps - step) / (total_steps - warmup_steps))
            
            self.scheduler = optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda)
        else:
            self.scheduler = None
    
    def train_epoch(self, epoch: int) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        epoch_losses = defaultdict(list)
        
        progress_bar = tqdm(self.train_dataloader, desc=f"Epoch {epoch}")
        
        for batch_idx, batch in enumerate(progress_bar):
            # å°†æ•°æ®ç§»åˆ°GPU
            batch = {k: v.to(self.device) if torch.is_tensor(v) else v for k, v in batch.items()}
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            
            outputs = self.model(
                video_frames=batch['video_features'],
                input_ids=batch['input_ids'],
                attention_mask=batch['attention_mask'],
                labels=batch['labels']
            )
            
            # è®¡ç®—æŸå¤±
            current_weights = self.loss_weight_scheduler.get_weights(
                self.train_stats['total_steps'], epoch
            )
            
            total_loss = self._compute_loss(outputs, current_weights)
            
            # åå‘ä¼ æ’­
            total_loss['total'].backward()
            
            # æ¢¯åº¦è£å‰ª
            if self.config['training_config'].get('max_grad_norm', 0) > 0:
                clip_grad_norm_(
                    self.model.parameters(), 
                    self.config['training_config']['max_grad_norm']
                )
            
            # ä¼˜åŒ–å™¨æ­¥è¿›
            self.optimizer.step()
            if self.scheduler is not None:
                self.scheduler.step()
            
            # è®°å½•æŸå¤±
            for key, value in total_loss.items():
                epoch_losses[key].append(value.item())
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.train_stats['total_steps'] += 1
            current_lr = self.optimizer.param_groups[0]['lr']
            self.train_stats['learning_rates'].append(current_lr)
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'loss': f"{total_loss['total'].item():.4f}",
                'lr': f"{current_lr:.2e}",
                'ntlbg': f"{total_loss.get('ntlbg', 0):.4f}" if 'ntlbg' in total_loss else 0
            })
            
            # æ—¥å¿—è®°å½•
            if batch_idx % self.config['logging_config']['log_interval'] == 0:
                self.logger.info(
                    f"Epoch {epoch}, Step {self.train_stats['total_steps']}, "
                    f"Loss: {total_loss['total'].item():.4f}, "
                    f"LR: {current_lr:.2e}"
                )
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_losses = {key: np.mean(values) for key, values in epoch_losses.items()}
        
        return avg_losses
    
    def _compute_loss(self, outputs: Dict, weights: Dict[str, float]) -> Dict[str, torch.Tensor]:
        """è®¡ç®—å¤šä»»åŠ¡æŸå¤±"""
        losses = {}
        
        # ä»æ¨¡å‹è¾“å‡ºä¸­æå–æŸå¤±
        loss_components = outputs.get('loss_components', {})
        
        # ä»»åŠ¡æŸå¤±
        task_loss = loss_components.get('task_loss', torch.tensor(0.0, device=self.device))
        losses['task'] = task_loss
        
        # NTLBGçº¦æŸæŸå¤±
        ntlbg_loss = loss_components.get('ntlbg_loss', torch.tensor(0.0, device=self.device))
        losses['ntlbg'] = ntlbg_loss
        
        # ç‰¹å¾å¯¹é½æŸå¤±
        alignment_loss = loss_components.get('alignment_loss', torch.tensor(0.0, device=self.device))
        losses['alignment'] = alignment_loss
        
        # æ—¶åºè¿è´¯æ€§æŸå¤±
        temporal_loss = loss_components.get('temporal_loss', torch.tensor(0.0, device=self.device))
        losses['temporal'] = temporal_loss
        
        # ä¿¡æ¯ä¿æŒæŸå¤±
        info_loss = loss_components.get('info_loss', torch.tensor(0.0, device=self.device))
        losses['info'] = info_loss
        
        # è®¡ç®—æ€»æŸå¤±
        total_loss = (
            weights.get('task', 1.0) * losses['task'] +
            weights.get('ntlbg', 0.5) * losses['ntlbg'] +
            weights.get('alignment', 0.3) * losses['alignment'] +
            weights.get('temporal', 0.2) * losses['temporal'] +
            weights.get('info', 0.1) * losses['info']
        )
        losses['total'] = total_loss
        
        return losses
    
    def validate(self, epoch: int) -> Dict[str, float]:
        """éªŒè¯æ¨¡å‹"""
        self.model.eval()
        val_losses = defaultdict(list)
        
        with torch.no_grad():
            for batch in tqdm(self.val_dataloader, desc="Validation"):
                batch = {k: v.to(self.device) if torch.is_tensor(v) else v for k, v in batch.items()}
                
                outputs = self.model(
                    video_frames=batch['video_features'],
                    input_ids=batch['input_ids'],
                    attention_mask=batch['attention_mask'],
                    labels=batch['labels']
                )
                
                # ä½¿ç”¨å½“å‰æƒé‡è®¡ç®—æŸå¤±
                current_weights = self.loss_weight_scheduler.get_weights(
                    self.train_stats['total_steps'], epoch
                )
                total_loss = self._compute_loss(outputs, current_weights)
                
                for key, value in total_loss.items():
                    val_losses[key].append(value.item())
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_val_losses = {key: np.mean(values) for key, values in val_losses.items()}
        
        return avg_val_losses
    
    def save_checkpoint(self, epoch: int, val_loss: float, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'val_loss': val_loss,
            'train_stats': self.train_stats,
            'config': self.config
        }
        
        # ä¿å­˜å½“å‰æ£€æŸ¥ç‚¹
        checkpoint_path = os.path.join(self.config['output_dir'], f'checkpoint_epoch_{epoch}.pt')
        torch.save(checkpoint, checkpoint_path)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = os.path.join(self.config['output_dir'], 'best_model.pt')
            torch.save(checkpoint, best_path)
            self.best_model_path = best_path
            self.logger.info(f"New best model saved with val_loss: {val_loss:.4f}")
        
        self.logger.info(f"Checkpoint saved: {checkpoint_path}")
    
    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        self.logger.info("Starting training...")
        self.logger.info(f"Total epochs: {self.config['training_config']['num_epochs']}")
        self.logger.info(f"Total training steps: {len(self.train_dataloader) * self.config['training_config']['num_epochs']}")
        
        for epoch in range(self.config['training_config']['num_epochs']):
            self.train_stats['epoch'] = epoch
            
            # è®­ç»ƒ
            train_losses = self.train_epoch(epoch)
            
            # éªŒè¯
            val_losses = self.validate(epoch)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
            current_val_loss = val_losses['total']
            is_best = current_val_loss < self.best_val_loss
            if is_best:
                self.best_val_loss = current_val_loss
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            if epoch % self.config['logging_config']['save_interval'] == 0:
                self.save_checkpoint(epoch, current_val_loss, is_best)
            
            # è®°å½•æ—¥å¿—
            self.logger.info(f"Epoch {epoch}")
            self.logger.info(f"Train - Total: {train_losses['total']:.4f}, Task: {train_losses['task']:.4f}, "
                           f"NTLBG: {train_losses.get('ntlbg', 0):.4f}")
            self.logger.info(f"Val - Total: {val_losses['total']:.4f}, Task: {val_losses['task']:.4f}, "
                           f"NTLBG: {val_losses.get('ntlbg', 0):.4f}")
        
        self.logger.info("Training completed!")
        self.logger.info(f"Best validation loss: {self.best_val_loss:.4f}")


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="è®­ç»ƒNTLBG-LLMæ¨¡å‹")
    parser.add_argument(
        "--config", 
        type=str, 
        required=True,
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--debug", 
        action="store_true",
        help="è°ƒè¯•æ¨¡å¼ï¼šä½¿ç”¨å°æ•°æ®é›†å¿«é€Ÿæµ‹è¯•"
    )
    parser.add_argument(
        "--dry_run", 
        action="store_true",
        help="å¹²è¿è¡Œï¼šåªéªŒè¯é…ç½®å’Œæ•°æ®åŠ è½½"
    )
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # åŠ è½½é…ç½®
    print(f"åŠ è½½é…ç½®æ–‡ä»¶: {args.config}")
    with open(args.config, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    # è°ƒè¯•æ¨¡å¼è®¾ç½®
    if args.debug:
        print("ğŸ› è°ƒè¯•æ¨¡å¼å¯ç”¨")
        config['training_config']['num_epochs'] = 2
        config['training_config']['batch_size'] = 2
        config['data_config']['max_video_frames'] = 20
        config['logging_config']['use_wandb'] = False
    
    # è®¾ç½®éšæœºç§å­
    set_seed(config['training_config']['seed'])
    
    # è·å–è®¾å¤‡ä¿¡æ¯
    device = get_device_info()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(config['output_dir'], exist_ok=True)
    
    # ä¿å­˜é…ç½®æ–‡ä»¶å‰¯æœ¬
    config_save_path = os.path.join(config['output_dir'], 'config.json')
    with open(config_save_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    try:
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print("ğŸ“ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        train_dataloader, val_dataloader, test_dataloader = create_dataloaders(config)
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_dataloader.dataset)}")
        print(f"éªŒè¯æ ·æœ¬æ•°: {len(val_dataloader.dataset)}")
        print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_dataloader.dataset)}")
        
        if args.dry_run:
            print("âœ… å¹²è¿è¡Œå®Œæˆï¼šæ•°æ®åŠ è½½æ­£å¸¸")
            return
        
        # åˆ›å»ºæ¨¡å‹
        print("ğŸ¤– åˆ›å»ºNTLBG-LLMæ¨¡å‹...")
        model = create_ntlbg_llm(config['model_config'])
        print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M")
        print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.1f}M")
        
        # åˆ›å»ºè®­ç»ƒå™¨
        print("ğŸƒ åˆ›å»ºè®­ç»ƒå™¨...")
        trainer = NTLBGTrainer(
            model=model,
            train_dataloader=train_dataloader,
            val_dataloader=val_dataloader,
            config=config,
            device=device
        )
        
        # å¼€å§‹è®­ç»ƒ
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        trainer.train()
        
        print("âœ… è®­ç»ƒå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main() 