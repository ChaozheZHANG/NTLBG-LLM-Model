import torch
from ntlbg_llm_adapter import create_ntlbg_adapter

print("ğŸ” æµ‹è¯•è®­ç»ƒå™¨processorä½¿ç”¨...")

# åˆ›å»ºæ¨¡å‹
model = create_ntlbg_adapter('qwen2vl')

# æ¨¡æ‹Ÿè®­ç»ƒå™¨ä¸­çš„æ•°æ®
questions = ["What is shown in the video?"]
options = [["A) A car", "B) A tree", "C) A house", "D) A person"]]

text_inputs = []
for i, question in enumerate(questions):
    full_text = f"Question: {question}\nOptions: " + " ".join([f"{chr(65+j)}) {opt}" for j, opt in enumerate(options[i])])
    text_inputs.append(full_text)

try:
    # æµ‹è¯•processorè°ƒç”¨
    processed_inputs = model.processor(
        text=text_inputs,
        return_tensors="pt",
        padding=True,
        truncation=True
    )
    print(f"âœ… processorè°ƒç”¨æˆåŠŸ: {list(processed_inputs.keys())}")
    
    # æµ‹è¯•æ˜¯å¦èƒ½ä¼ é€’ç»™æ¨¡å‹
    with torch.no_grad():
        outputs = model(**processed_inputs)
    print(f"âœ… æ¨¡å‹è°ƒç”¨æˆåŠŸ")
    
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("ğŸ” æµ‹è¯•å®Œæˆ")
