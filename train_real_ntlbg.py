"""
çœŸæ­£çš„NTLBG-LLMè®­ç»ƒè„šæœ¬
"""
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
import os
import sys
from tqdm import tqdm
import json
import numpy as np
from datetime import datetime

# å¯¼å…¥ä¿®å¤åçš„ç»„ä»¶
sys.path.append('src/data')
from fixed_dataset import FixedNTLBGDataset

# å¯¼å…¥æ¨¡å‹
from create_real_ntlbg_llm import RealNTLBGLLM

class NTLBGTrainer:
    def __init__(self, config):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # åˆ›å»ºæ¨¡å‹
        self.model = RealNTLBGLLM(config).to(self.device)
        
        # åˆ›å»ºæ•°æ®é›†
        self.train_dataset = FixedNTLBGDataset(
            "/workspace/NTLBG-LLM/data", 
            split="train",
            max_frames=config.get('max_frames', 16)
        )
        
        self.val_dataset = FixedNTLBGDataset(
            "/workspace/NTLBG-LLM/data",
            split="val", 
            max_frames=config.get('max_frames', 16)
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=config.get('batch_size', 2),
            shuffle=True,
            num_workers=2,
            collate_fn=self.collate_fn
        )
        
        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=config.get('batch_size', 2),
            shuffle=False,
            num_workers=2,
            collate_fn=self.collate_fn
        )
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=config.get('learning_rate', 1e-4),
            weight_decay=config.get('weight_decay', 0.01)
        )
        
        print(f"âœ… è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   è®­ç»ƒæ ·æœ¬: {len(self.train_dataset)}")
        print(f"   éªŒè¯æ ·æœ¬: {len(self.val_dataset)}")
    
    def collate_fn(self, batch):
        """æ•°æ®æ‰¹å¤„ç†"""
        video_frames = []
        texts = []
        questions = []
        answers = []
        
        for sample in batch:
            video_frames.append(sample['video_frames'])
            texts.append(sample['text'] + " " + sample['question'])
            questions.append(sample['question'])
            answers.append(sample['answer'])
        
        return {
            'video_frames': video_frames,
            'texts': texts,
            'questions': questions,
            'answers': torch.tensor(answers)
        }
    
    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        num_batches = 0
        
        progress_bar = tqdm(self.train_loader, desc="Training")
        
        for batch in progress_bar:
            self.optimizer.zero_grad()
            
            batch_loss = 0
            batch_size = len(batch['texts'])
            
            for i in range(batch_size):
                try:
                    # å‰å‘ä¼ æ’­
                    outputs = self.model(
                        video_frames=batch['video_frames'][i],
                        text_input=batch['texts'][i],
                        questions=batch['questions'][i]
                    )
                    
                    # è®¡ç®—æŸå¤± (ç®€å•çš„åˆ†ç±»æŸå¤±)
                    logits = outputs['logits']
                    target = batch['answers'][i].to(self.device)
                    
                    # å‡è®¾æ˜¯4é€‰æ‹©é¢˜
                    if logits.shape[-1] >= 4:
                        loss = F.cross_entropy(logits[:, :4], target.unsqueeze(0))
                    else:
                        # ä½¿ç”¨MSEæŸå¤±ä½œä¸ºå¤‡é€‰
                        loss = F.mse_loss(logits.float(), target.float().unsqueeze(0))
                    
                    batch_loss += loss
                    
                except Exception as e:
                    print(f"âŒ è®­ç»ƒæ ·æœ¬{i}å¤±è´¥: {e}")
                    # åˆ›å»ºå‡æŸå¤±é¿å…è®­ç»ƒä¸­æ–­
                    batch_loss += torch.tensor(0.0, requires_grad=True).to(self.device)
            
            # å¹³å‡æ‰¹æ¬¡æŸå¤±
            if batch_size > 0:
                batch_loss = batch_loss / batch_size
                
                # åå‘ä¼ æ’­
                batch_loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
                self.optimizer.step()
                
                total_loss += batch_loss.item()
                num_batches += 1
                
                progress_bar.set_postfix({'loss': batch_loss.item()})
        
        return total_loss / max(num_batches, 1)
    
    def evaluate(self):
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch in tqdm(self.val_loader, desc="Evaluating"):
                batch_size = len(batch['texts'])
                
                for i in range(batch_size):
                    try:
                        outputs = self.model(
                            video_frames=batch['video_frames'][i],
                            text_input=batch['texts'][i]
                        )
                        
                        logits = outputs['logits']
                        target = batch['answers'][i]
                        
                        if logits.shape[-1] >= 4:
                            pred = torch.argmax(logits[:, :4], dim=-1)
                            correct += (pred == target).sum().item()
                        
                        total += 1
                        
                    except Exception as e:
                        print(f"âŒ è¯„ä¼°æ ·æœ¬{i}å¤±è´¥: {e}")
        
        accuracy = correct / max(total, 1)
        return accuracy
    
    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print("ğŸš€ å¼€å§‹NTLBG-LLMè®­ç»ƒ")
        
        num_epochs = self.config.get('num_epochs', 3)
        best_accuracy = 0
        
        results = {
            'train_losses': [],
            'val_accuracies': [],
            'best_accuracy': 0,
            'training_time': datetime.now().isoformat()
        }
        
        for epoch in range(num_epochs):
            print(f"\nğŸ“š Epoch {epoch+1}/{num_epochs}")
            
            # è®­ç»ƒ
            train_loss = self.train_epoch()
            print(f"   è®­ç»ƒæŸå¤±: {train_loss:.4f}")
            
            # è¯„ä¼°
            val_accuracy = self.evaluate()
            print(f"   éªŒè¯å‡†ç¡®ç‡: {val_accuracy:.4f}")
            
            # è®°å½•ç»“æœ
            results['train_losses'].append(train_loss)
            results['val_accuracies'].append(val_accuracy)
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_accuracy > best_accuracy:
                best_accuracy = val_accuracy
                results['best_accuracy'] = best_accuracy
                
                os.makedirs("models", exist_ok=True)
                torch.save(self.model.state_dict(), "models/best_ntlbg_llm.pth")
                print(f"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡: {best_accuracy:.4f})")
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        with open("training_results.json", "w") as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"   æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.4f}")
        
        return results

def main():
    config = {
        'batch_size': 2,  # H200æ˜¾å­˜å¤§ï¼Œå¯ä»¥å¢åŠ 
        'learning_rate': 5e-5,
        'num_epochs': 5,
        'max_frames': 16,
        'num_representatives': 6,
        'weight_decay': 0.01
    }
    
    try:
        trainer = NTLBGTrainer(config)
        results = trainer.train()
        
        print("\nğŸ“Š è®­ç»ƒç»“æœ:")
        print(f"   æœ€ä½³å‡†ç¡®ç‡: {results['best_accuracy']:.4f}")
        print(f"   è®­ç»ƒæŸå¤±: {results['train_losses']}")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
