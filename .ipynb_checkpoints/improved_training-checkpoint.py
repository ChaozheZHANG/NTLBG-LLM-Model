"""
æ”¹è¿›çš„NTLBG-LLMè®­ç»ƒè„šæœ¬ - é¿å…è¿‡æ‹Ÿåˆ
"""
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset
import os
import sys
from tqdm import tqdm
import json
import numpy as np
from datetime import datetime
import random

# æ·»åŠ è·¯å¾„
sys.path.append('/workspace/NTLBG-LLM')
sys.path.append('/workspace/NTLBG-LLM/LongVideoBench_official')

# å¯¼å…¥å®˜æ–¹æ•°æ®åŠ è½½å™¨
from longvideobench import LongVideoBenchDataset
from create_real_ntlbg_llm import RealNTLBGLLM

class ImprovedNTLBGTrainer:
    def __init__(self, config):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆ›å»ºæ¨¡å‹
        print("ğŸ”¨ åˆ›å»ºNTLBG-LLMæ¨¡å‹...")
        self.model = RealNTLBGLLM(config).to(self.device)
        
        # åˆ›å»ºçœŸå®æ•°æ®é›†
        self.create_real_datasets()
        
        # ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=config.get('learning_rate', 1e-5),  # æ›´å°çš„å­¦ä¹ ç‡
            weight_decay=config.get('weight_decay', 0.01)
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, 
            T_max=config.get('num_epochs', 5)
        )
        
        print(f"âœ… æ”¹è¿›è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def create_real_datasets(self):
        """åˆ›å»ºçœŸå®çš„æ•°æ®é›†"""
        data_path = "/workspace/NTLBG-LLM/data/longvideobench"
        
        try:
            # åŠ è½½å®Œæ•´éªŒè¯é›†
            full_val_dataset = LongVideoBenchDataset(
                data_path, 
                "lvb_val.json", 
                max_num_frames=16
            )
            
            # å°†éªŒè¯é›†åˆ†ä¸ºè®­ç»ƒå’ŒéªŒè¯
            total_val = len(full_val_dataset)
            train_size = int(0.8 * total_val)  # 80%ç”¨äºè®­ç»ƒ
            val_size = total_val - train_size
            
            # éšæœºåˆ†å‰²
            indices = list(range(total_val))
            random.shuffle(indices)
            
            train_indices = indices[:train_size]
            val_indices = indices[train_size:]
            
            self.train_dataset = Subset(full_val_dataset, train_indices)
            self.val_dataset = Subset(full_val_dataset, val_indices)
            
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨
            self.train_loader = DataLoader(
                self.train_dataset,
                batch_size=self.config.get('batch_size', 2),
                shuffle=True,
                num_workers=0,
                collate_fn=self.collate_fn
            )
            
            self.val_loader = DataLoader(
                self.val_dataset,
                batch_size=self.config.get('batch_size', 2),
                shuffle=False,
                num_workers=0,
                collate_fn=self.collate_fn
            )
            
            print(f"âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆ:")
            print(f"   è®­ç»ƒæ ·æœ¬: {len(self.train_dataset)}")
            print(f"   éªŒè¯æ ·æœ¬: {len(self.val_dataset)}")
            
        except Exception as e:
            print(f"âŒ çœŸå®æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
            # ä½¿ç”¨ç®€å•æ•°æ®é›†ä½œä¸ºå¤‡é€‰
            self.create_simple_datasets()
    
    def create_simple_datasets(self):
        """åˆ›å»ºç®€å•æ•°æ®é›†ä½œä¸ºå¤‡é€‰"""
        from fixed_dataset import FixedNTLBGDataset
        
        self.train_dataset = FixedNTLBGDataset(
            "/workspace/NTLBG-LLM/data",
            split="train"
        )
        self.val_dataset = FixedNTLBGDataset(
            "/workspace/NTLBG-LLM/data", 
            split="val"
        )
        
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=self.config.get('batch_size', 2),
            shuffle=True,
            collate_fn=self.simple_collate_fn
        )
        
        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=self.config.get('batch_size', 2),
            shuffle=False,
            collate_fn=self.simple_collate_fn
        )
    
    def collate_fn(self, batch):
        """å¤„ç†LongVideoBenchæ•°æ®"""
        processed_batch = []
        
        for sample in batch:
            try:
                inputs = sample.get("inputs", [])
                
                # åˆ†ç¦»è§†é¢‘å¸§å’Œæ–‡æœ¬
                video_frames = []
                text_parts = []
                
                for item in inputs:
                    if hasattr(item, 'size'):  # PIL Image
                        video_frames.append(item)
                    elif isinstance(item, str):
                        text_parts.append(item)
                
                combined_text = " ".join(text_parts)
                answer = sample.get('answer', 0)
                if isinstance(answer, (list, tuple)):
                    answer = answer[0] if len(answer) > 0 else 0
                
                processed_batch.append({
                    'video_frames': video_frames,
                    'text': combined_text,
                    'answer': int(answer)
                })
                
            except Exception as e:
                print(f"âŒ æ‰¹å¤„ç†æ ·æœ¬å¤±è´¥: {e}")
                # æ·»åŠ ç©ºæ ·æœ¬
                processed_batch.append({
                    'video_frames': [],
                    'text': "empty sample",
                    'answer': 0
                })
        
        return processed_batch
    
    def simple_collate_fn(self, batch):
        """å¤„ç†ç®€å•æ•°æ®"""
        processed_batch = []
        for sample in batch:
            processed_batch.append({
                'video_frames': sample.get('video_frames', []),
                'text': sample.get('text', '') + " " + sample.get('question', ''),
                'answer': sample.get('answer', 0)
            })
        return processed_batch
    
    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        num_batches = 0
        
        progress_bar = tqdm(self.train_loader, desc="Training")
        
        for batch in progress_bar:
            self.optimizer.zero_grad()
            
            batch_loss = 0
            valid_samples = 0
            
            for sample in batch:
                try:
                    # å‰å‘ä¼ æ’­
                    outputs = self.model(
                        video_frames=sample['video_frames'],
                        text_input=sample['text']
                    )
                    
                    # è®¡ç®—æŸå¤±
                    logits = outputs['logits']
                    target = torch.tensor(sample['answer'], device=self.device)
                    
                    # ç¡®ä¿ç»´åº¦æ­£ç¡®
                    if logits.dim() == 1:
                        logits = logits.unsqueeze(0)
                    
                    # å¤šé€‰æ‹©é¢˜æŸå¤±
                    if logits.shape[-1] >= 4:
                        choice_logits = logits[:, :4]
                        loss = F.cross_entropy(choice_logits, target.unsqueeze(0))
                    else:
                        # MSEå¤‡é€‰
                        loss = F.mse_loss(logits.float(), target.float().unsqueeze(0).unsqueeze(0))
                    
                    batch_loss += loss
                    valid_samples += 1
                    
                except Exception as e:
                    # è·³è¿‡æœ‰é—®é¢˜çš„æ ·æœ¬
                    continue
            
            # åªæœ‰å½“æœ‰æœ‰æ•ˆæ ·æœ¬æ—¶æ‰æ›´æ–°
            if valid_samples > 0:
                batch_loss = batch_loss / valid_samples
                
                # åå‘ä¼ æ’­
                batch_loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)
                self.optimizer.step()
                
                total_loss += batch_loss.item()
                num_batches += 1
                
                progress_bar.set_postfix({'loss': f'{batch_loss.item():.4f}'})
        
        return total_loss / max(num_batches, 1)
    
    def evaluate(self):
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch in tqdm(self.val_loader, desc="Evaluating"):
                for sample in batch:
                    try:
                        outputs = self.model(
                            video_frames=sample['video_frames'],
                            text_input=sample['text']
                        )
                        
                        logits = outputs['logits']
                        target = sample['answer']
                        
                        if logits.shape[-1] >= 4:
                            pred = torch.argmax(logits[:, :4], dim=-1).cpu().item()
                            correct += (pred == target)
                        
                        total += 1
                        
                    except Exception as e:
                        total += 1  # è®¡æ•°ä½†ä¸åŠ åˆ†
        
        return correct / max(total, 1)
    
    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print("ğŸš€ å¼€å§‹æ”¹è¿›çš„NTLBG-LLMè®­ç»ƒ")
        print("=" * 60)
        
        num_epochs = self.config.get('num_epochs', 10)
        best_accuracy = 0
        patience = 3
        patience_counter = 0
        
        results = {
            'train_losses': [],
            'val_accuracies': [],
            'best_accuracy': 0,
            'training_time': datetime.now().isoformat(),
            'config': self.config
        }
        
        for epoch in range(num_epochs):
            print(f"\nğŸ“š Epoch {epoch+1}/{num_epochs}")
            print(f"   å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.2e}")
            print("-" * 40)
            
            # è®­ç»ƒ
            train_loss = self.train_epoch()
            print(f"   âœ… è®­ç»ƒæŸå¤±: {train_loss:.4f}")
            
            # è¯„ä¼°
            val_accuracy = self.evaluate()
            print(f"   âœ… éªŒè¯å‡†ç¡®ç‡: {val_accuracy:.4f}")
            
            # å­¦ä¹ ç‡è°ƒæ•´
            self.scheduler.step()
            
            # è®°å½•ç»“æœ
            results['train_losses'].append(train_loss)
            results['val_accuracies'].append(val_accuracy)
            
            # æ—©åœæ£€æŸ¥
            if val_accuracy > best_accuracy:
                best_accuracy = val_accuracy
                results['best_accuracy'] = best_accuracy
                patience_counter = 0
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                os.makedirs("outputs/models", exist_ok=True)
                torch.save(self.model.state_dict(), "outputs/models/improved_ntlbg_llm.pth")
                print(f"   ğŸ¯ ä¿å­˜æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡: {best_accuracy:.4f})")
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print(f"   ğŸ›‘ æ—©åœï¼š{patience}ä¸ªepochæ²¡æœ‰æ”¹è¿›")
                    break
        
        # ä¿å­˜ç»“æœ
        with open("outputs/improved_training_results.json", "w") as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ‰ æ”¹è¿›è®­ç»ƒå®Œæˆ!")
        print(f"   ğŸ† æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.4f}")
        
        return results

def main():
    config = {
        'batch_size': 2,
        'learning_rate': 1e-5,  # æ›´å°çš„å­¦ä¹ ç‡
        'num_epochs': 10,
        'max_frames': 16,
        'num_representatives': 6,
        'weight_decay': 0.01
    }
    
    trainer = ImprovedNTLBGTrainer(config)
    results = trainer.train()
    
    return results

if __name__ == "__main__":
    main()
